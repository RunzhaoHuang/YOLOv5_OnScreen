{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.7.0+cpu cpu\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import win32api\n",
    "import sys\n",
    "#sys.path.append(r'C:\\Users\\ray\\Desktop\\yolov5-master')\n",
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import torch\n",
    "from IPython.display import Image, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "from utils.general import check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, \\\n",
    "    strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' %(torch.__version__,\n",
    "                                            torch.cuda_get_device_properties(0) if torch.cuda.is_available() else 'cpu'))\n",
    "import os\n",
    "#os.chdir(r'C:\\Users\\ray\\Desktop\\yolov5-master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    }
   ],
   "source": [
    "#%% Detect objects on screen\n",
    "\n",
    "# Initialize\n",
    "device = select_device()\n",
    "# Load model\n",
    "model = attempt_load('yolov5s.pt', map_location=device)     # load FP32 model cuda\n",
    "\n",
    "# Get names and colors\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "colors = [[random.randint(0, 225) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "def process_img(original_image):\n",
    "    processed_img = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    processed_img = cv2.resize(processed_img, (800, 480))\n",
    "    return processed_img\n",
    "\n",
    "while True:\n",
    "    #time.sleep(1)\n",
    "    #win32api.keybd_event(87, 0, 0, 0)\n",
    "    printscreen_pil = np.array(ImageGrab.grab(bbox = (400, 360, 1600, 1080)))\n",
    "    #print('printscreen_pil:', np.shape(printscreen_pil))\n",
    "    frame = process_img(printscreen_pil)\n",
    "    #print(....\n",
    "    #\n",
    "    img = frame.copy()     \n",
    "    #print(..\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()       # uint8 to fp32\n",
    "    img /= 255.0\n",
    "\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    pred = model(img)[0]\n",
    "    pred = non_max_suppression(pred, 0.4, 0.5)\n",
    "\n",
    "    gn = torch.tensor(frame.shape)[[1, 0, 1, 0]]  # get the size of image\n",
    "    if pred != [None]:\n",
    "        for i, det in enumerate(pred):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:,:4] = scale_coords(img.shape[2:], det[:, :4], printscreen_pil.shape).round()\n",
    "            #write results\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh \n",
    "                label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                plot_one_box(xyxy, printscreen_pil, label = label, color = colors[int(cls)], line_thickness = 1)  # utils.general \n",
    "\n",
    "    cv2.imshow('capture', printscreen_pil[:, :, ::-1])\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "#cap.release()\n",
    "cv2.destroyWindow(winname='capture')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect object using webcam\n",
    "\n",
    "# Initialize\n",
    "device = select_device()\n",
    "# Load model\n",
    "model = attempt_load('yolov5s.pt', map_location = device) # load FP32 model cuda\n",
    "# Get names and colors\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(1):\n",
    "    # get a frame\n",
    "    ret, frame = cap.read()\n",
    "    # processing\n",
    "    img = frame.copy()     \n",
    "    img = np.transpose(img, (2,0,1))    # torch.Size([480, 640, 3]) to torch.Size([3, 480, 640])\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()   # uint8 to fp32\n",
    "    img /= 255.0\n",
    "\n",
    "    #print(np.shape(img))\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)     \n",
    "    #\n",
    "    pred = model(img)[0]\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, 0.4, 0.5)      # threshold =0.4\n",
    "    # Drawing\n",
    "    gn = torch.tensor(frame.shape)[[1, 0, 1, 0]]  \n",
    "    if pred != [None]:\n",
    "        for i, det in enumerate(pred):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:,:4] = scale_coords(img.shape[2:], det[:, :4], frame.shape).round()\n",
    "            #write results\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh \n",
    "                label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                plot_one_box(xyxy, frame, label = label, color = colors[int(cls)], line_thickness = 1)  # utils.general \n",
    "    # show a frame\n",
    "    cv2.imshow('capture', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# cap.release()\n",
    "cv2.destroyWindow(winname='capture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection on Screen with alert area\n",
    "\n",
    "#%%\n",
    "# Detect object on Screen, and set an alert area to mark down object number changes\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "import time\n",
    "import win32api\n",
    "import torch\n",
    "#import torch.backends.cudnn as cudnn\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import (check_img_size, non_max_suppression, scale_coords)\n",
    "from utils.torch_utils import select_device, load_classifier\n",
    "from utils.plots import plot_one_box\n",
    "print('Setup complete. Using torch %s %s' %(torch.__version__,\n",
    "                                            torch.cuda_get_device_properties(0) if torch.cuda.is_available() else 'cpu'))\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\ray\\Desktop\\Screen_object_detection\\yolov5-master')\n",
    "\n",
    "\n",
    "# Initialize\n",
    "device = select_device()\n",
    "frame_h = 666\n",
    "frame_w = 1184\n",
    "obj_count = 0   # object number in alert area\n",
    "obj_count_old = 0    \n",
    "take_photo_num = 0  \n",
    "# Each detection may not capture every object all the timeso we set a buf, fer to take the average value, because we want to avoid the loss of the target in a frame.\n",
    "obj_count_buf = np.array([0,0,0,0,0,0,0,0,0,0])     \n",
    "\n",
    "# load the model\n",
    "model = attempt_load('yolov5s.pt', map_location = device) # load FP32 model cuda\n",
    "# Get names and colors\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "colors = [[random.randint(0, 225) for _ in range(3)] for _ in range(len(names))]\n",
    "# imgsz = check_img_size(486, s=model.stride.max())  # check img_size\n",
    "\n",
    "frame_mask = np.zeros((frame_h, frame_w, 3), dtype = np.uint8)  # Make a mask with the same size\n",
    "position = [(300, 300), (300, 500), (500, 500), (500, 300)]     # Four points defines a alert area\n",
    "cv2.fillPoly(frame_mask, [np.array(position)], (0, 0, 255))     # The color inside the alert area is (0, 0, 255)\n",
    "\n",
    "def process_img(original_image):    # Process the original frame/image\n",
    "    processed_img = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    processed_img = cv2.resize(processed_img, (frame_w, frame_h))\n",
    "    return processed_img\n",
    "\n",
    "def MouseEvent(a, b, c, d, e):  # Mouse response function\n",
    "    if(a==1):   # Click left button to get the coordinates\n",
    "        print(b, c)\n",
    "\n",
    "cv2.namedWindow('frame')\n",
    "cv2.setMouseCallback('frame', MouseEvent)   \n",
    "while True:\n",
    "    # get a frame\n",
    "    start = time.time()\n",
    "    frame = np.array(ImageGrab.grab(bbox = (225, 225, 1416, 894)))\n",
    "    if np.shape(frame):     \n",
    "        #processing\n",
    "        frame = process_img(frame)\n",
    "        img = frame.copy()  # img is in gpu format, which cannot be read by conventional methods\n",
    "        img = np.transpose(img, (2,0,1))    # torch.Size([480, 800, 3]) to torch.Size([3, 480, 800])\n",
    "        img = torch.from_numpy(img).to(device) \n",
    "        img = img.float()   # uint8 to fp32\n",
    "        img /= 255.0   # 0 - 255 to 0.0 - 1.0\n",
    "        #print()\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)   # Add one dimension to img \n",
    "        pred = model(img)[0]\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, 0.4, 0.5)  # Output shreshold > 0.4\n",
    "        \n",
    "        # Drawing\n",
    "        if pred != [None]:\n",
    "            for i, det in enumerate(pred):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], frame.shape).round()\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):     # But it looks like you can also use det instead of reversed(det)         \n",
    "                    if cls == 0: # Here, cls=0 means we only care about the class 'person'\n",
    "                        # label = '%s %.2f' % (names[int(cls)], conf) \n",
    "                        label = f'{names[int(cls)]}' \n",
    "                        plot_one_box(xyxy, frame, label = label, color = colors[int(cls)], line_thickness = 1) # utils.general\n",
    "                        xy = torch.tensor(xyxy).tolist()    \n",
    "                        x, y, x1, y1 = int(xy[0]), int(xy[1]), int(xy[2]), int(xy[3])  # Retrieve the coordinates of the bbox\n",
    "                        center_xy = (int(np.average([x, x1])), int(np.average([y, y1])))  # calculate the center point\n",
    "                        if (frame_mask[(center_xy[1], center_xy[0])] == [0, 0, 255]).all():  # If the center of the object lies inside the alert area\n",
    "                            obj_color = (0, 0, 255)     # Change the color of the object center\n",
    "                            obj_count +=1\n",
    "                        else:\n",
    "                            obj_color = (0, 255, 0)   # Else it reminds normal color\n",
    "                        cv2.circle(frame, center_xy, 3, obj_color, -1)      # Draw a circle for object center\n",
    "        obj_count_buf = np.append(obj_count_buf[1:], obj_count)     # Update the buffer\n",
    "        cbr = int(np.around(np.average(obj_count_buf)))\n",
    "        end = time.time()\n",
    "        fps = 1 / (end - start)  # Calculate the fps\n",
    "        fps = \"%.2f fps\"%fps        \n",
    "        cv2.putText(frame, 'fps:%s  obj_count:%s  take_photo:%s' % (fps, cbr, take_photo_num), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "        frame = cv2.addWeighted(frame, 1.0, frame_mask, 0.1, 0.0)   # Draw a mask\n",
    "        if (obj_count_old != cbr):\n",
    "            take_photo_num += 1\n",
    "            cv2.imwrite(\"./photo/%s.jpg\" % take_photo_num, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])  # Save screencapture\n",
    "            print('take photo number :%s' % take_photo_num)  # Display the total number of photo taken\n",
    "            cv2.putText(frame, 'Alert', (250, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)  \n",
    "        \n",
    "        obj_count_old = cbr  \n",
    "        obj_count = 0  # Clear the obj_count in this frame, waiting for another detection for the next frame\n",
    "        \n",
    "        # show a frame\n",
    "        # cv2.imshow()\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.imshow(\"frame_mask\", frame_mask[:, :, ::-1])\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyWindow(winname='frame')\n",
    "cv2.destroyWindow(winname='frame_mask')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
